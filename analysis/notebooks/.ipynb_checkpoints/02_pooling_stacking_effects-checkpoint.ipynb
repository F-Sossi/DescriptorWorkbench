{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling and Stacking Effects Analysis\n",
    "\n",
    "This notebook focuses specifically on analyzing the effects of different pooling strategies and descriptor stacking on performance.\n",
    "\n",
    "## Key Research Questions:\n",
    "1. **Pooling Impact**: How does Domain-Size Pooling (DSP) affect descriptor performance?\n",
    "2. **Stacking Benefits**: Does stacking descriptors improve robustness and accuracy?\n",
    "3. **Interaction Effects**: How do pooling strategies interact with different descriptor types?\n",
    "4. **Computational Trade-offs**: Performance gains vs computational cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Database connection\n",
    "DB_PATH = \"../../build/experiments.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess experiment data with focus on pooling strategies\n",
    "def load_pooling_analysis_data():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        e.id as experiment_id,\n",
    "        e.descriptor_type,\n",
    "        e.pooling_strategy,\n",
    "        e.dataset_name,\n",
    "        r.mean_average_precision,\n",
    "        r.precision_at_1,\n",
    "        r.precision_at_5,\n",
    "        r.precision_at_10,\n",
    "        r.recall_at_1,\n",
    "        r.recall_at_5,\n",
    "        r.total_matches,\n",
    "        r.total_keypoints,\n",
    "        r.processing_time_ms\n",
    "    FROM experiments e \n",
    "    JOIN results r ON e.id = r.experiment_id\n",
    "    WHERE e.pooling_strategy IN ('none', 'domain_size_pooling', 'stacking')\n",
    "    ORDER BY e.descriptor_type, e.pooling_strategy\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    # Clean and enhance data\n",
    "    pooling_map = {\n",
    "        'none': 'None',\n",
    "        'domain_size_pooling': 'DSP',\n",
    "        'stacking': 'Stacking'\n",
    "    }\n",
    "    df['pooling_clean'] = df['pooling_strategy'].map(pooling_map)\n",
    "    \n",
    "    # Extract base descriptor info\n",
    "    df['base_descriptor'] = df['descriptor_type'].str.extract(r'(sift|rgbsift)', expand=False).str.upper().fillna('SIFT')\n",
    "    df['uses_color'] = df['descriptor_type'].str.contains('rgb', case=False)\n",
    "    \n",
    "    # Calculate performance improvements\n",
    "    baseline_performance = df[df['pooling_clean'] == 'None'].groupby('base_descriptor')['mean_average_precision'].mean()\n",
    "    \n",
    "    def calculate_improvement(row):\n",
    "        baseline = baseline_performance.get(row['base_descriptor'], row['mean_average_precision'])\n",
    "        return (row['mean_average_precision'] - baseline) / baseline * 100\n",
    "    \n",
    "    df['map_improvement_pct'] = df.apply(calculate_improvement, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_pooling = load_pooling_analysis_data()\n",
    "print(f\"Loaded {len(df_pooling)} experiments for pooling analysis\")\n",
    "print(f\"Pooling strategies: {sorted(df_pooling['pooling_clean'].unique())}\")\n",
    "df_pooling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Strategy Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive pooling effects visualization\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. MAP comparison across pooling strategies\n",
    "plt.subplot(2, 3, 1)\n",
    "pooling_comparison = df_pooling.groupby(['pooling_clean', 'base_descriptor'])['mean_average_precision'].mean().unstack()\n",
    "pooling_comparison.plot(kind='bar', ax=plt.gca(), width=0.8)\n",
    "plt.title('Mean Average Precision by Pooling Strategy', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Mean Average Precision')\n",
    "plt.xlabel('Pooling Strategy')\n",
    "plt.legend(title='Base Descriptor')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 2. Precision@K comparison\n",
    "plt.subplot(2, 3, 2)\n",
    "precision_metrics = ['precision_at_1', 'precision_at_5']\n",
    "precision_data = df_pooling.groupby('pooling_clean')[precision_metrics].mean()\n",
    "x = np.arange(len(precision_data.index))\n",
    "width = 0.35\n",
    "plt.bar(x - width/2, precision_data['precision_at_1'], width, label='P@1', alpha=0.8)\n",
    "plt.bar(x + width/2, precision_data['precision_at_5'], width, label='P@5', alpha=0.8)\n",
    "plt.xlabel('Pooling Strategy')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision@K by Pooling Strategy', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x, precision_data.index)\n",
    "plt.legend()\n",
    "\n",
    "# 3. Performance improvement heatmap\n",
    "plt.subplot(2, 3, 3)\n",
    "improvement_pivot = df_pooling.pivot_table(\n",
    "    values='map_improvement_pct', \n",
    "    index='pooling_clean', \n",
    "    columns='base_descriptor', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "sns.heatmap(improvement_pivot, annot=True, cmap='RdYlGn', center=0, fmt='.1f')\n",
    "plt.title('MAP Improvement (%) over Baseline', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Pooling Strategy')\n",
    "\n",
    "# 4. Processing time vs performance trade-off\n",
    "plt.subplot(2, 3, 4)\n",
    "for pooling in df_pooling['pooling_clean'].unique():\n",
    "    data = df_pooling[df_pooling['pooling_clean'] == pooling]\n",
    "    plt.scatter(data['processing_time_ms']/1000, data['mean_average_precision'], \n",
    "               label=pooling, alpha=0.7, s=60)\n",
    "plt.xlabel('Processing Time (seconds)')\n",
    "plt.ylabel('Mean Average Precision')\n",
    "plt.title('Performance vs Processing Time Trade-off', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "\n",
    "# 5. Descriptor dimension effects (if stacking changes dimensions)\n",
    "plt.subplot(2, 3, 5)\n",
    "keypoint_efficiency = df_pooling.groupby('pooling_clean').agg({\n",
    "    'mean_average_precision': 'mean',\n",
    "    'total_keypoints': 'mean'\n",
    "}).reset_index()\n",
    "plt.scatter(keypoint_efficiency['total_keypoints'], keypoint_efficiency['mean_average_precision'], s=100)\n",
    "for i, txt in enumerate(keypoint_efficiency['pooling_clean']):\n",
    "    plt.annotate(txt, (keypoint_efficiency['total_keypoints'].iloc[i], \n",
    "                      keypoint_efficiency['mean_average_precision'].iloc[i]),\n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "plt.xlabel('Average Total Keypoints')\n",
    "plt.ylabel('Mean Average Precision')\n",
    "plt.title('Keypoint Usage Efficiency', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 6. Box plot of MAP distribution by pooling strategy\n",
    "plt.subplot(2, 3, 6)\n",
    "sns.boxplot(data=df_pooling, x='pooling_clean', y='mean_average_precision')\n",
    "plt.title('MAP Distribution by Pooling Strategy', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Pooling Strategy')\n",
    "plt.ylabel('Mean Average Precision')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis of Pooling Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical analysis of pooling strategy effects\n",
    "print(\"=== POOLING STRATEGY EFFECTS ANALYSIS ===\")\n",
    "\n",
    "# 1. Overall performance by pooling strategy\n",
    "print(\"\\n1. Performance Summary by Pooling Strategy:\")\n",
    "pooling_summary = df_pooling.groupby('pooling_clean').agg({\n",
    "    'mean_average_precision': ['mean', 'std', 'count'],\n",
    "    'precision_at_1': ['mean', 'std'],\n",
    "    'precision_at_5': ['mean', 'std'],\n",
    "    'processing_time_ms': ['mean', 'std'],\n",
    "    'map_improvement_pct': ['mean', 'std']\n",
    "}).round(4)\n",
    "print(pooling_summary)\n",
    "\n",
    "# 2. Statistical significance testing\n",
    "print(\"\\n2. Statistical Significance Tests (ANOVA):\")\n",
    "pooling_groups = [group['mean_average_precision'].values for name, group in df_pooling.groupby('pooling_clean')]\n",
    "f_stat, p_value = stats.f_oneway(*pooling_groups)\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Significant difference: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# 3. Pairwise comparisons\n",
    "print(\"\\n3. Pairwise Performance Comparisons:\")\n",
    "pooling_strategies = df_pooling['pooling_clean'].unique()\n",
    "for i, strategy1 in enumerate(pooling_strategies):\n",
    "    for strategy2 in pooling_strategies[i+1:]:\n",
    "        group1 = df_pooling[df_pooling['pooling_clean'] == strategy1]['mean_average_precision']\n",
    "        group2 = df_pooling[df_pooling['pooling_clean'] == strategy2]['mean_average_precision']\n",
    "        \n",
    "        if len(group1) > 1 and len(group2) > 1:\n",
    "            t_stat, p_val = stats.ttest_ind(group1, group2)\n",
    "            mean_diff = group1.mean() - group2.mean()\n",
    "            print(f\"{strategy1} vs {strategy2}: Mean diff = {mean_diff:.4f}, p = {p_val:.4f}\")\n",
    "\n",
    "# 4. Effect sizes\n",
    "print(\"\\n4. Effect Sizes (Cohen's d):\")\n",
    "none_group = df_pooling[df_pooling['pooling_clean'] == 'None']['mean_average_precision']\n",
    "for strategy in ['DSP', 'Stacking']:\n",
    "    if strategy in df_pooling['pooling_clean'].values:\n",
    "        treatment_group = df_pooling[df_pooling['pooling_clean'] == strategy]['mean_average_precision']\n",
    "        if len(treatment_group) > 0 and len(none_group) > 0:\n",
    "            pooled_std = np.sqrt(((len(none_group)-1)*none_group.var() + \n",
    "                                 (len(treatment_group)-1)*treatment_group.var()) / \n",
    "                                (len(none_group) + len(treatment_group) - 2))\n",
    "            cohens_d = (treatment_group.mean() - none_group.mean()) / pooled_std\n",
    "            print(f\"{strategy} vs None: Cohen's d = {cohens_d:.3f}\")\n",
    "            effect_size = \"Small\" if abs(cohens_d) < 0.5 else \"Medium\" if abs(cohens_d) < 0.8 else \"Large\"\n",
    "            print(f\"  Effect size: {effect_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction Effects Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze interaction between pooling strategies and descriptor characteristics\n",
    "print(\"=== INTERACTION EFFECTS ANALYSIS ===\")\n",
    "\n",
    "# 1. Pooling × Color interaction\n",
    "print(\"\\n1. Pooling Strategy × Color Usage Interaction:\")\n",
    "interaction_data = df_pooling.groupby(['pooling_clean', 'uses_color'])['mean_average_precision'].agg(['mean', 'std', 'count'])\n",
    "print(interaction_data.round(4))\n",
    "\n",
    "# Visualize interaction\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Interaction plot\n",
    "for color_usage in [True, False]:\n",
    "    data = df_pooling[df_pooling['uses_color'] == color_usage]\n",
    "    pooling_means = data.groupby('pooling_clean')['mean_average_precision'].mean()\n",
    "    axes[0].plot(pooling_means.index, pooling_means.values, \n",
    "                marker='o', linewidth=2, markersize=8,\n",
    "                label=f\"{'Color' if color_usage else 'Grayscale'}\")\n",
    "\n",
    "axes[0].set_xlabel('Pooling Strategy')\n",
    "axes[0].set_ylabel('Mean Average Precision')\n",
    "axes[0].set_title('Pooling × Color Usage Interaction', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Heatmap of interaction effects\n",
    "interaction_pivot = df_pooling.pivot_table(\n",
    "    values='mean_average_precision', \n",
    "    index='pooling_clean', \n",
    "    columns='uses_color', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "sns.heatmap(interaction_pivot, annot=True, cmap='Blues', fmt='.3f', ax=axes[1])\n",
    "axes[1].set_title('Performance Heatmap: Pooling × Color', fontweight='bold')\n",
    "axes[1].set_xlabel('Uses Color')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Best performing combinations\n",
    "print(\"\\n2. Top Performing Descriptor + Pooling Combinations:\")\n",
    "combination_performance = df_pooling.groupby(['descriptor_type', 'pooling_clean']).agg({\n",
    "    'mean_average_precision': 'mean',\n",
    "    'precision_at_1': 'mean',\n",
    "    'processing_time_ms': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "top_combinations = combination_performance.nlargest(5, 'mean_average_precision')\n",
    "print(top_combinations.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export pooling analysis results\n",
    "output_dir = Path(\"../outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save detailed pooling analysis data\n",
    "df_pooling.to_csv(output_dir / \"pooling_effects_analysis.csv\", index=False)\n",
    "\n",
    "# Save summary statistics\n",
    "pooling_summary.to_csv(output_dir / \"pooling_strategy_summary.csv\")\n",
    "\n",
    "# Save top combinations\n",
    "top_combinations.to_csv(output_dir / \"top_descriptor_pooling_combinations.csv\", index=False)\n",
    "\n",
    "print(f\"\\nPooling analysis results exported to {output_dir}\")\n",
    "print(f\"Key findings:\")\n",
    "print(f\"- Total experiments analyzed: {len(df_pooling)}\")\n",
    "print(f\"- Pooling strategies tested: {len(df_pooling['pooling_clean'].unique())}\")\n",
    "print(f\"- Descriptor variations: {len(df_pooling['descriptor_type'].unique())}\")\n",
    "print(f\"- Best performing combination: {top_combinations.iloc[0]['descriptor_type']} with {top_combinations.iloc[0]['pooling_clean']} (MAP: {top_combinations.iloc[0]['mean_average_precision']:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}