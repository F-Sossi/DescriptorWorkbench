{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic Descriptor Modification Analysis\n",
    "\n",
    "This notebook analyzes the systematic effects of individual modifications to SIFT descriptors, allowing us to isolate the contribution of each enhancement.\n",
    "\n",
    "## Analysis Framework:\n",
    "1. **Baseline Establishment**: Pure SIFT performance\n",
    "2. **Single Modification Effects**: Individual impact of each change\n",
    "3. **Combination Effects**: How modifications interact\n",
    "4. **Performance Attribution**: Which modifications contribute most to accuracy gains\n",
    "\n",
    "## Modifications Analyzed:\n",
    "- **Color**: Grayscale (SIFT) vs Color (RGBSIFT)\n",
    "- **Pooling**: None vs Domain-Size Pooling vs Stacking\n",
    "- **Normalization**: L1 vs L2 norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"Set1\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Database connection\n",
    "DB_PATH = \"../../build/experiments.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load systematic analysis data\ndef load_systematic_analysis_data():\n    conn = sqlite3.connect(DB_PATH)\n    \n    query = \"\"\"\n    SELECT \n        e.id as experiment_id,\n        e.descriptor_type,\n        e.pooling_strategy,\n        e.dataset_name,\n        e.similarity_threshold,\n        e.max_features,\n        r.mean_average_precision,\n        r.true_map_macro,\n        r.true_map_micro,\n        r.true_map_macro_with_zeros,\n        r.true_map_micro_with_zeros,\n        r.legacy_mean_precision,\n        r.precision_at_1,\n        r.precision_at_5,\n        r.recall_at_1,\n        r.recall_at_5,\n        r.total_matches,\n        r.total_keypoints,\n        r.processing_time_ms,\n        r.metadata\n    FROM experiments e \n    JOIN results r ON e.id = r.experiment_id\n    ORDER BY r.mean_average_precision DESC\n    \"\"\"\n    \n    df = pd.read_sql_query(query, conn)\n    conn.close()\n    \n    # Use primary columns directly, with fallback to legacy for older records\n    df['macro_map'] = df['true_map_macro'].fillna(df['mean_average_precision'])\n    df['micro_map'] = df['true_map_micro'].fillna(df['mean_average_precision'])\n    df['macro_map_with_zeros'] = df['true_map_macro_with_zeros']\n    df['micro_map_with_zeros'] = df['true_map_micro_with_zeros']\n    \n    return df\n\n# Parse descriptor configurations\ndef parse_descriptor_config(descriptor_name):\n    \"\"\"Extract configuration from descriptor names\"\"\"\n    config = {\n        'base_type': 'SIFT',\n        'uses_color': False,\n        'normalization': 'L2',\n        'pooling': 'None'\n    }\n    \n    name_lower = descriptor_name.lower()\n    \n    # Base type\n    if 'rgbsift' in name_lower or 'color' in name_lower:\n        config['base_type'] = 'RGBSIFT'\n        config['uses_color'] = True\n    \n    # Normalization\n    if 'l1' in name_lower:\n        config['normalization'] = 'L1'\n    \n    return config\n\n# Load and process data\ndf_systematic = load_systematic_analysis_data()\n\n# Parse configurations\nconfig_df = pd.DataFrame([parse_descriptor_config(name) for name in df_systematic['descriptor_type']])\ndf_systematic = pd.concat([df_systematic, config_df], axis=1)\n\n# Clean pooling strategy names\npooling_map = {\n    'none': 'None',\n    'domain_size_pooling': 'DSP',\n    'stacking': 'Stacking'\n}\ndf_systematic['pooling_clean'] = df_systematic['pooling_strategy'].map(pooling_map).fillna(df_systematic['pooling_strategy'])\ndf_systematic['pooling'] = df_systematic['pooling_clean']\n\nprint(f\"Loaded {len(df_systematic)} experiments for systematic analysis\")\nprint(\"Available MAP metrics (using primary columns):\")\nprint(f\"- Primary MAP: {df_systematic['mean_average_precision'].min():.4f} - {df_systematic['mean_average_precision'].max():.4f}\")\nprint(f\"- Macro MAP: {df_systematic['macro_map'].min():.4f} - {df_systematic['macro_map'].max():.4f}\")\nprint(f\"- Micro MAP: {df_systematic['micro_map'].min():.4f} - {df_systematic['micro_map'].max():.4f}\")\ndf_systematic.head(10)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Establish baseline performance using macro MAP\nbaseline_condition = (df_systematic['base_type'] == 'SIFT') & \\\n                    (df_systematic['pooling'] == 'None') & \\\n                    (df_systematic['normalization'] == 'L2')\n\nbaseline_performance = df_systematic[baseline_condition]['macro_map'].iloc[0] if baseline_condition.any() else 0.36\n\nprint(f\"=== BASELINE PERFORMANCE ===\")\nprint(f\"Baseline configuration: SIFT + Grayscale + No Pooling + L2 Norm\")\nprint(f\"Baseline Macro MAP: {baseline_performance:.4f}\")\n\n# Calculate improvement over baseline for all configurations\ndf_systematic['map_improvement'] = df_systematic['macro_map'] - baseline_performance\ndf_systematic['map_improvement_pct'] = (df_systematic['map_improvement'] / baseline_performance) * 100\n\nprint(f\"\\nTop 5 performing configurations:\")\n# Use dropna to handle NaN values in macro_map\nvalid_data = df_systematic.dropna(subset=['macro_map'])\ntop_5 = valid_data.nlargest(5, 'macro_map')[['descriptor_type', 'pooling_clean', 'macro_map', 'map_improvement_pct']]\nfor i, row in top_5.iterrows():\n    print(f\"{row['descriptor_type']} ({row['pooling_clean']}): Macro MAP = {row['macro_map']:.4f} (+{row['map_improvement_pct']:.1f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Modification Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Analyze individual modification effects\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\nfig.suptitle('Individual Modification Effects on Descriptor Performance', fontsize=16, fontweight='bold')\n\n# Filter valid data\nvalid_data = df_systematic.dropna(subset=['macro_map'])\n\n# 1. Color effect (SIFT vs RGBSIFT)\ncolor_effect = valid_data.groupby(['uses_color', 'pooling', 'normalization'])['macro_map'].mean().reset_index()\ncolor_comparison = color_effect.groupby('uses_color')['macro_map'].mean()\n\nif len(color_comparison) >= 2:\n    axes[0,0].bar(['Grayscale (SIFT)', 'Color (RGBSIFT)'], color_comparison.values, \n                 color=['lightblue', 'salmon'], alpha=0.8)\n    for i, v in enumerate(color_comparison.values):\n        axes[0,0].text(i, v + 0.005, f'{v:.3f}', ha='center', fontweight='bold')\nelse:\n    # Only one color type available\n    color_name = 'Color (RGBSIFT)' if color_comparison.index[0] else 'Grayscale (SIFT)'\n    axes[0,0].bar([color_name], color_comparison.values, color=['lightblue'], alpha=0.8)\n    axes[0,0].text(0, color_comparison.values[0] + 0.005, f'{color_comparison.values[0]:.3f}', ha='center', fontweight='bold')\n\naxes[0,0].set_title('Color vs Grayscale Effect', fontweight='bold')\naxes[0,0].set_ylabel('Macro MAP')\n\n# 2. Pooling strategy effect\npooling_effect = valid_data.groupby('pooling')['macro_map'].mean().sort_values(ascending=False)\ncolors = ['lightcoral', 'lightgreen', 'lightskyblue'][:len(pooling_effect)]\nbars = axes[0,1].bar(pooling_effect.index, pooling_effect.values, color=colors, alpha=0.8)\naxes[0,1].set_title('Pooling Strategy Effect', fontweight='bold')\naxes[0,1].set_ylabel('Macro MAP')\naxes[0,1].set_xlabel('Pooling Strategy')\nfor i, v in enumerate(pooling_effect.values):\n    axes[0,1].text(i, v + 0.005, f'{v:.3f}', ha='center', fontweight='bold')\n\n# 3. Normalization effect\nnorm_effect = valid_data.groupby('normalization')['macro_map'].mean()\nnorm_colors = ['lightsteelblue', 'lightcoral'][:len(norm_effect)]\naxes[1,0].bar(norm_effect.index, norm_effect.values, color=norm_colors, alpha=0.8)\naxes[1,0].set_title('Normalization Effect', fontweight='bold')\naxes[1,0].set_ylabel('Macro MAP')\naxes[1,0].set_xlabel('Normalization Type')\nfor i, v in enumerate(norm_effect.values):\n    axes[1,0].text(i, v + 0.005, f'{v:.3f}', ha='center', fontweight='bold')\n\n# 4. Improvement magnitude comparison\nimprovements = {}\n\n# Color improvement\nif len(color_comparison) >= 2:\n    improvements['Color'] = (color_comparison[True] - color_comparison[False]) / baseline_performance * 100\n\n# Pooling improvements\nif 'DSP' in pooling_effect.index and 'None' in pooling_effect.index:\n    improvements['DSP'] = (pooling_effect['DSP'] - pooling_effect['None']) / baseline_performance * 100\n\nif 'Stacking' in pooling_effect.index and 'None' in pooling_effect.index:\n    improvements['Stacking'] = (pooling_effect['Stacking'] - pooling_effect['None']) / baseline_performance * 100\n\n# Normalization improvement\nif len(norm_effect) >= 2:\n    if 'L1' in norm_effect.index and 'L2' in norm_effect.index:\n        improvements['L1 Norm'] = (norm_effect['L1'] - norm_effect['L2']) / baseline_performance * 100\n\n# Filter out missing values and sort by improvement\nimprovements = {k: v for k, v in improvements.items() if not pd.isna(v)}\nimprovements = dict(sorted(improvements.items(), key=lambda x: x[1], reverse=True))\n\nif improvements:\n    colors = ['green' if v > 0 else 'red' for v in improvements.values()]\n    bars = axes[1,1].bar(improvements.keys(), improvements.values(), color=colors, alpha=0.7)\n    axes[1,1].set_title('Performance Improvement by Modification', fontweight='bold')\n    axes[1,1].set_ylabel('Improvement over Baseline (%)')\n    axes[1,1].set_xlabel('Modification Type')\n    axes[1,1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n    for i, (k, v) in enumerate(improvements.items()):\n        axes[1,1].text(i, v + (0.2 if v > 0 else -0.2), f'{v:.1f}%', ha='center', fontweight='bold')\nelse:\n    axes[1,1].text(0.5, 0.5, 'Insufficient data\\nfor comparison', ha='center', va='center', \n                   transform=axes[1,1].transAxes, fontsize=12)\n    axes[1,1].set_title('Performance Improvement by Modification', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Print numerical results\nprint(\"\\n=== INDIVIDUAL MODIFICATION EFFECTS ===\")\nif improvements:\n    for modification, improvement in improvements.items():\n        print(f\"{modification}: {improvement:+.1f}% change vs baseline\")\nelse:\n    print(\"Insufficient data for individual modification analysis\")\n    print(\"Available configurations:\")\n    for i, row in valid_data.iterrows():\n        color_str = \"Color\" if row['uses_color'] else \"Grayscale\"\n        print(f\"  {color_str} + {row['pooling']} + {row['normalization']}: {row['macro_map']:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination Effects Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze combination effects and interactions\n",
    "print(\"=== COMBINATION EFFECTS ANALYSIS ===\")\n",
    "\n",
    "# Create a comprehensive combination analysis\n",
    "combination_analysis = df_systematic.groupby(['uses_color', 'pooling', 'normalization']).agg({\n",
    "    'mean_average_precision': ['mean', 'count'],\n",
    "    'map_improvement_pct': 'mean',\n",
    "    'processing_time_ms': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "combination_analysis.columns = ['MAP', 'Count', 'Improvement_%', 'ProcessTime_ms']\n",
    "combination_analysis = combination_analysis.reset_index().sort_values('MAP', ascending=False)\n",
    "\n",
    "print(\"\\nTop performing combinations:\")\n",
    "print(combination_analysis.head(10))\n",
    "\n",
    "# Visualize combination effects with interactive plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Create traces for different combinations\n",
    "for i, row in combination_analysis.iterrows():\n",
    "    color_str = \"Color\" if row['uses_color'] else \"Gray\"\n",
    "    hover_text = f\"{color_str} + {row['pooling']} + {row['normalization']}<br>\" \\\n",
    "                f\"MAP: {row['MAP']:.4f}<br>\" \\\n",
    "                f\"Improvement: {row['Improvement_%']:+.1f}%<br>\" \\\n",
    "                f\"Processing: {row['ProcessTime_ms']:.0f}ms\"\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[row['ProcessTime_ms']/1000],  # Convert to seconds\n",
    "        y=[row['MAP']],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=15,\n",
    "            color=row['Improvement_%'],\n",
    "            colorscale='RdYlGn',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Improvement %\")\n",
    "        ),\n",
    "        text=hover_text,\n",
    "        hovertemplate='%{text}<extra></extra>',\n",
    "        name=f\"{color_str}+{row['pooling']}+{row['normalization']}\",\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Descriptor Configuration Performance vs Processing Time',\n",
    "    xaxis_title='Processing Time (seconds)',\n",
    "    yaxis_title='Mean Average Precision',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Analyze synergistic effects\n",
    "print(\"\\n=== SYNERGISTIC EFFECTS ===\")\n",
    "print(\"Expected vs Actual performance for combinations:\")\n",
    "\n",
    "# Calculate expected performance if effects were purely additive\n",
    "for i, row in combination_analysis.head(5).iterrows():\n",
    "    expected_improvement = 0\n",
    "    \n",
    "    # Add individual effects\n",
    "    if row['uses_color']:\n",
    "        expected_improvement += improvements.get('Color', 0)\n",
    "    \n",
    "    if row['pooling'] == 'DSP':\n",
    "        expected_improvement += improvements.get('DSP', 0)\n",
    "    elif row['pooling'] == 'Stacking':\n",
    "        expected_improvement += improvements.get('Stacking', 0)\n",
    "    \n",
    "    if row['normalization'] == 'L1':\n",
    "        expected_improvement += improvements.get('L1 Norm', 0)\n",
    "    \n",
    "    expected_map = baseline_performance * (1 + expected_improvement/100)\n",
    "    actual_map = row['MAP']\n",
    "    synergy = actual_map - expected_map\n",
    "    \n",
    "    color_str = \"Color\" if row['uses_color'] else \"Gray\"\n",
    "    config_name = f\"{color_str}+{row['pooling']}+{row['normalization']}\"\n",
    "    \n",
    "    print(f\"{config_name}:\")\n",
    "    print(f\"  Expected MAP: {expected_map:.4f}\")\n",
    "    print(f\"  Actual MAP: {actual_map:.4f}\")\n",
    "    print(f\"  Synergy: {synergy:+.4f} ({synergy/baseline_performance*100:+.1f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Attribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance attribution waterfall chart\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Get the best performing configuration\n",
    "best_config = combination_analysis.iloc[0]\n",
    "best_map = best_config['MAP']\n",
    "\n",
    "print(f\"=== PERFORMANCE ATTRIBUTION ===\")\n",
    "print(f\"Best configuration: {'Color' if best_config['uses_color'] else 'Gray'} + {best_config['pooling']} + {best_config['normalization']}\")\n",
    "print(f\"Best MAP: {best_map:.4f} vs Baseline: {baseline_performance:.4f}\")\n",
    "print(f\"Total improvement: {(best_map - baseline_performance)/baseline_performance*100:.1f}%\")\n",
    "\n",
    "# Create waterfall data\n",
    "waterfall_data = [\n",
    "    {'category': 'Baseline\\n(SIFT+Gray+None+L2)', 'value': baseline_performance, 'type': 'absolute'},\n",
    "]\n",
    "\n",
    "# Add contributions from best config\n",
    "running_total = baseline_performance\n",
    "\n",
    "if best_config['uses_color']:\n",
    "    color_contribution = improvements.get('Color', 0) / 100 * baseline_performance\n",
    "    waterfall_data.append({'category': '+Color\\n(RGBSIFT)', 'value': color_contribution, 'type': 'relative'})\n",
    "    running_total += color_contribution\n",
    "\n",
    "if best_config['pooling'] != 'None':\n",
    "    pooling_contribution = improvements.get(best_config['pooling'], 0) / 100 * baseline_performance\n",
    "    waterfall_data.append({'category': f'+{best_config[\"pooling\"]}\\nPooling', 'value': pooling_contribution, 'type': 'relative'})\n",
    "    running_total += pooling_contribution\n",
    "\n",
    "if best_config['normalization'] != 'L2':\n",
    "    norm_contribution = improvements.get('L1 Norm', 0) / 100 * baseline_performance\n",
    "    waterfall_data.append({'category': f'+{best_config[\"normalization\"]}\\nNorm', 'value': norm_contribution, 'type': 'relative'})\n",
    "    running_total += norm_contribution\n",
    "\n",
    "# Add synergy effect\n",
    "synergy = best_map - running_total\n",
    "if abs(synergy) > 0.001:\n",
    "    waterfall_data.append({'category': 'Synergy\\nEffects', 'value': synergy, 'type': 'relative'})\n",
    "\n",
    "waterfall_data.append({'category': 'Final\\nPerformance', 'value': best_map, 'type': 'absolute'})\n",
    "\n",
    "# Create waterfall chart\n",
    "categories = [item['category'] for item in waterfall_data]\n",
    "values = [item['value'] for item in waterfall_data]\n",
    "types = [item['type'] for item in waterfall_data]\n",
    "\n",
    "# Calculate cumulative values for plotting\n",
    "cumulative = []\n",
    "running = 0\n",
    "for i, (val, typ) in enumerate(zip(values, types)):\n",
    "    if typ == 'absolute':\n",
    "        cumulative.append(val)\n",
    "        running = val\n",
    "    else:\n",
    "        cumulative.append(running + val)\n",
    "        running += val\n",
    "\n",
    "fig = go.Figure(go.Waterfall(\n",
    "    name=\"Performance Attribution\",\n",
    "    orientation=\"v\",\n",
    "    measure=[\"absolute\"] + [\"relative\"] * (len(categories)-2) + [\"total\"],\n",
    "    x=categories,\n",
    "    text=[f\"{v:.4f}\" for v in values],\n",
    "    y=values,\n",
    "    connector={\"line\":{\"color\":\"rgb(63, 63, 63)\"}},\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Performance Attribution: From Baseline to Best Configuration\",\n",
    "    yaxis_title=\"Mean Average Precision\",\n",
    "    xaxis_title=\"Configuration Components\",\n",
    "    showlegend=False,\n",
    "    width=800,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Print attribution breakdown\n",
    "print(\"\\nPerformance attribution breakdown:\")\n",
    "total_improvement = best_map - baseline_performance\n",
    "for item in waterfall_data[1:-1]:  # Skip baseline and final\n",
    "    contribution_pct = (item['value'] / total_improvement) * 100 if total_improvement != 0 else 0\n",
    "    print(f\"{item['category']}: {item['value']:+.4f} MAP ({contribution_pct:.1f}% of total improvement)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export systematic analysis results\n",
    "output_dir = Path(\"../outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save comprehensive analysis data\n",
    "df_systematic.to_csv(output_dir / \"systematic_modification_analysis.csv\", index=False)\n",
    "\n",
    "# Save combination analysis\n",
    "combination_analysis.to_csv(output_dir / \"descriptor_combination_analysis.csv\", index=False)\n",
    "\n",
    "# Save individual modification effects\n",
    "improvement_df = pd.DataFrame(list(improvements.items()), columns=['Modification', 'Improvement_Pct'])\n",
    "improvement_df.to_csv(output_dir / \"individual_modification_effects.csv\", index=False)\n",
    "\n",
    "# Create summary report\n",
    "with open(output_dir / \"systematic_analysis_summary.txt\", 'w') as f:\n",
    "    f.write(\"SYSTEMATIC DESCRIPTOR MODIFICATION ANALYSIS\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"BASELINE PERFORMANCE:\\n\")\n",
    "    f.write(f\"Configuration: SIFT + Grayscale + No Pooling + L2 Norm\\n\")\n",
    "    f.write(f\"MAP: {baseline_performance:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"BEST CONFIGURATION:\\n\")\n",
    "    best_desc = \"Color\" if best_config['uses_color'] else \"Grayscale\"\n",
    "    f.write(f\"Configuration: {best_desc} + {best_config['pooling']} + {best_config['normalization']}\\n\")\n",
    "    f.write(f\"MAP: {best_map:.4f}\\n\")\n",
    "    f.write(f\"Total Improvement: {(best_map - baseline_performance)/baseline_performance*100:.1f}%\\n\\n\")\n",
    "    \n",
    "    f.write(\"INDIVIDUAL MODIFICATION EFFECTS:\\n\")\n",
    "    for mod, imp in improvements.items():\n",
    "        f.write(f\"{mod}: {imp:+.1f}%\\n\")\n",
    "\n",
    "print(f\"\\n=== ANALYSIS COMPLETE ===\")\n",
    "print(f\"Results exported to: {output_dir}\")\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"- Baseline MAP: {baseline_performance:.3f}\")\n",
    "print(f\"- Best MAP: {best_map:.3f} (+{(best_map-baseline_performance)/baseline_performance*100:.1f}%)\")\n",
    "print(f\"- Most effective modification: {max(improvements.items(), key=lambda x: x[1])[0]} (+{max(improvements.values()):.1f}%)\")\n",
    "print(f\"- Experiments analyzed: {len(df_systematic)}\")\n",
    "print(f\"- Unique configurations: {len(combination_analysis)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}